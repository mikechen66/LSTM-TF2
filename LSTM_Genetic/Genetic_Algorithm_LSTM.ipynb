{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v7cP8t8mEXsp"
   },
   "source": [
    "### Optimizing RNN using Genetic Algorithm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z6VW1YmBEXsr"
   },
   "source": [
    "#### Importing required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "SfFSvEwDGDy3",
    "outputId": "73430628-ee03-4c9b-feec-45f211b87736"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: deap in /home/mike/miniconda3/lib/python3.7/site-packages (1.3.1)\r\n",
      "Requirement already satisfied: numpy in /home/mike/miniconda3/lib/python3.7/site-packages (from deap) (1.18.5)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install deap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "X8TMoirqGpEo",
    "outputId": "b391e5b0-f783-4836-e57b-bb913c02ae63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bitstring in /home/mike/miniconda3/lib/python3.7/site-packages (3.1.7)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install bitstring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R4yL2aYREXst"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split as split\n",
    "\n",
    "from tensorflow.keras.layers import LSTM, Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf \n",
    "\n",
    "from deap import base, creator, tools, algorithms\n",
    "from scipy.stats import bernoulli\n",
    "from bitstring import BitArray\n",
    "\n",
    "np.random.seed(1120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w8mHU56dE2er"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "img_dir = '/tmp/nst'\n",
    "if not os.path.exists(img_dir):\n",
    "    os.makedirs(img_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the GPU growth to avoid a sudden stop of the runtime with the reminding \n",
    "# message: Could not create cuDNN handle.\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vAz1i7VMgFkm"
   },
   "source": [
    "### Collecting the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7c_On5F7E4Ds"
   },
   "outputs": [],
   "source": [
    "fget=1\n",
    "if fget>0:\n",
    "  !wget --quiet -P /tmp/nst/ https://eco-ai-horizons.com/img/train.csv\n",
    "fn=img_dir+'/train.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-F0G5igKEXsz"
   },
   "source": [
    "#### Reading dataset and using first 17,257 points as training/validation and rest of the 1500 points as test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xNX8b0ytEXs0"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(fn)\n",
    "data = np.reshape(np.array(data['wp1']),(len(data['wp1']),1))\n",
    "\n",
    "train_data = data[0:17257]\n",
    "test_data = data[17257:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FkJdlgMHEXs6"
   },
   "source": [
    "#### Defining the basic Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_uOsTtV0EXs7"
   },
   "outputs": [],
   "source": [
    "def prepare_dataset(data, window_size):\n",
    "    X, Y = np.empty((0,window_size)), np.empty((0))\n",
    "    for i in range(len(data)-window_size-1):\n",
    "        X = np.vstack([X,data[i:(i + window_size),0]])\n",
    "        Y = np.append(Y,data[i + window_size,0])   \n",
    "    X = np.reshape(X,(len(X),window_size,1))\n",
    "    Y = np.reshape(Y,(len(Y),1))\n",
    "    return X, Y\n",
    "\n",
    "def train_evaluate(ga_individual_solution):   \n",
    "    # Decode GA solution to integer for window_size and num_units\n",
    "    window_size_bits = BitArray(ga_individual_solution[0:6])\n",
    "    num_units_bits = BitArray(ga_individual_solution[6:]) \n",
    "    window_size = window_size_bits.uint\n",
    "    num_units = num_units_bits.uint\n",
    "    print('\\nWindow Size: ', window_size, ', Num of Units: ', num_units)\n",
    "    \n",
    "    # Return fitness score of 100 if window_size or num_unit is zero\n",
    "    if window_size == 0 or num_units == 0:\n",
    "        return 100, \n",
    "    \n",
    "    # Segment the train_data based on new window_size; split into train and validation (80/20)\n",
    "    X,Y = prepare_dataset(train_data,window_size)\n",
    "    X_train, X_val, y_train, y_val = split(X, Y, test_size = 0.20, random_state = 1120)\n",
    "    \n",
    "    # Train LSTM model and predict on validation set\n",
    "    inputs = Input(shape=(window_size,1))\n",
    "    x = LSTM(num_units, input_shape=(window_size,1))(inputs)\n",
    "    predictions = Dense(1, activation='linear')(x)\n",
    "    model = Model(inputs=inputs, outputs=predictions)\n",
    "    model.compile(optimizer='adam',loss='mean_squared_error')\n",
    "    model.fit(X_train, y_train, epochs=5, batch_size=10,shuffle=True)\n",
    "    y_pred = model.predict(X_val)\n",
    "    \n",
    "    # Calculate the RMSE score as fitness score for GA\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "    print('Validation RMSE: ', rmse,'\\n')\n",
    "    \n",
    "    return rmse,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-HVvKhrGEXs_"
   },
   "source": [
    "#### Evolutionary Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "lzs9dTg3EXtD",
    "outputId": "d250fbe9-3946-469e-e7a1-621d5fa634b7",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Window Size:  36 , Num of Units:  2\n",
      "Epoch 1/5\n",
      "1378/1378 [==============================] - 2s 2ms/step - loss: 0.0616\n",
      "Epoch 2/5\n",
      "1378/1378 [==============================] - 2s 2ms/step - loss: 0.0093\n",
      "Epoch 3/5\n",
      "1378/1378 [==============================] - 2s 2ms/step - loss: 0.0066\n",
      "Epoch 4/5\n",
      "1378/1378 [==============================] - 2s 2ms/step - loss: 0.0061\n",
      "Epoch 5/5\n",
      "1378/1378 [==============================] - 2s 2ms/step - loss: 0.0060\n",
      "Validation RMSE:  0.0769580578283086 \n",
      "\n",
      "\n",
      "Window Size:  56 , Num of Units:  8\n",
      "Epoch 1/5\n",
      "1376/1376 [==============================] - 2s 2ms/step - loss: 0.0201\n",
      "Epoch 2/5\n",
      "1376/1376 [==============================] - 2s 2ms/step - loss: 0.0069\n",
      "Epoch 3/5\n",
      "1376/1376 [==============================] - 2s 2ms/step - loss: 0.0060\n",
      "Epoch 4/5\n",
      "1376/1376 [==============================] - 2s 2ms/step - loss: 0.0059\n",
      "Epoch 5/5\n",
      "1376/1376 [==============================] - 2s 2ms/step - loss: 0.0058\n",
      "Validation RMSE:  0.07426257206078647 \n",
      "\n",
      "\n",
      "Window Size:  60 , Num of Units:  9\n",
      "Epoch 1/5\n",
      "1376/1376 [==============================] - 3s 2ms/step - loss: 0.0146\n",
      "Epoch 2/5\n",
      "1376/1376 [==============================] - 3s 2ms/step - loss: 0.0067\n",
      "Epoch 3/5\n",
      "1376/1376 [==============================] - 3s 2ms/step - loss: 0.0058\n",
      "Epoch 4/5\n",
      "1376/1376 [==============================] - 3s 2ms/step - loss: 0.0058\n",
      "Epoch 5/5\n",
      "1376/1376 [==============================] - 3s 2ms/step - loss: 0.0057\n",
      "Validation RMSE:  0.07909072941576117 \n",
      "\n",
      "\n",
      "Window Size:  49 , Num of Units:  9\n",
      "Epoch 1/5\n",
      "1377/1377 [==============================] - 3s 2ms/step - loss: 0.0150\n",
      "Epoch 2/5\n",
      "1377/1377 [==============================] - 3s 2ms/step - loss: 0.0062\n",
      "Epoch 3/5\n",
      "1377/1377 [==============================] - 3s 2ms/step - loss: 0.0058\n",
      "Epoch 4/5\n",
      "1377/1377 [==============================] - 3s 2ms/step - loss: 0.0058\n",
      "Epoch 5/5\n",
      "1377/1377 [==============================] - 3s 2ms/step - loss: 0.0057\n",
      "Validation RMSE:  0.0744113928159914 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "population_size = 4\n",
    "num_generations = 2\n",
    "gene_length = 10\n",
    "\n",
    "# As we are trying to minimize the RMSE score, that's why using -1.0. \n",
    "# In case, when you want to maximize accuracy for instance, use 1.0\n",
    "creator.create('FitnessMax', base.Fitness, weights = (-1.0,))\n",
    "creator.create('Individual', list , fitness = creator.FitnessMax)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register('binary', bernoulli.rvs, 0.5)\n",
    "toolbox.register('individual', tools.initRepeat, creator.Individual, toolbox.binary, n = gene_length)\n",
    "toolbox.register('population', tools.initRepeat, list , toolbox.individual)\n",
    "\n",
    "toolbox.register('mate', tools.cxOrdered)\n",
    "toolbox.register('mutate', tools.mutShuffleIndexes, indpb = 0.6)\n",
    "toolbox.register('select', tools.selRoulette)\n",
    "toolbox.register('evaluate', train_evaluate)\n",
    "\n",
    "population = toolbox.population(n = population_size)\n",
    "r = algorithms.eaSimple(population, toolbox, cxpb = 0.4, mutpb = 0.1, ngen = num_generations, verbose = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "asFxTbP6EXtG"
   },
   "source": [
    "#### Print top N solutions - (1st only, for now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "gU-VdzO0EXtH",
    "outputId": "01f6bfc8-3485-41e5-f6a2-bc4e2997bdb7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Window Size:  49 , Num of Units:  9\n"
     ]
    }
   ],
   "source": [
    "best_individuals = tools.selBest(population,k = 1)\n",
    "best_window_size = None\n",
    "best_num_units = None\n",
    "\n",
    "for bi in best_individuals:\n",
    "    window_size_bits = BitArray(bi[0:6])\n",
    "    num_units_bits = BitArray(bi[6:]) \n",
    "    best_window_size = window_size_bits.uint\n",
    "    best_num_units = num_units_bits.uint\n",
    "    print('\\nWindow Size: ', best_window_size, ', Num of Units: ', best_num_units)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xZBaQ4GOEXtM"
   },
   "source": [
    "#### Train the model using best configuration on complete training set and make predictions on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "0Pv_IgVaEXtO",
    "outputId": "24d45efe-9c32-42b8-e0d1-6ee1daa5c9d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1721/1721 [==============================] - 3s 2ms/step - loss: 0.0169\n",
      "Epoch 2/5\n",
      "1721/1721 [==============================] - 3s 2ms/step - loss: 0.0061\n",
      "Epoch 3/5\n",
      "1721/1721 [==============================] - 3s 2ms/step - loss: 0.0058\n",
      "Epoch 4/5\n",
      "1721/1721 [==============================] - 3s 2ms/step - loss: 0.0057\n",
      "Epoch 5/5\n",
      "1721/1721 [==============================] - 3s 2ms/step - loss: 0.0057\n",
      "Test RMSE:  0.09281258802857055\n"
     ]
    }
   ],
   "source": [
    "X_train,y_train = prepare_dataset(train_data,best_window_size)\n",
    "X_test, y_test = prepare_dataset(test_data,best_window_size)\n",
    "\n",
    "inputs = Input(shape=(best_window_size,1))\n",
    "x = LSTM(best_num_units, input_shape=(best_window_size,1))(inputs)\n",
    "predictions = Dense(1, activation='linear')(x)\n",
    "model = Model(inputs = inputs, outputs = predictions)\n",
    "model.compile(optimizer='adam',loss='mean_squared_error')\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=10,shuffle=True)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print('Test RMSE: ', rmse)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Genetic-Algorithm-LSTM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
