{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mike/miniconda3/lib/python3.7/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mike/miniconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.metrics.classification module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from data_preparation import Preprocessing\n",
    "from lstm_network import LSTM_RNN_Network\n",
    "import pickle\n",
    "import datetime\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior() \n",
    "import os\n",
    "from tensorflow.python.framework import ops\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.classification import accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the GPU to avoid the runtime error: Could not create cuDNN handle...\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS  \n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "ops.reset_default_graph()\n",
    "\n",
    "\n",
    "# Give the path to the three necessary directory. \n",
    "data_dir = '/home/mike/Documents/keras_lstm/LSTM_Sentiment/data/'  \n",
    "stopwords_file = '/home/mike/Documents/keras_lstm/LSTM_Sentiment/data/stopwords.txt' \n",
    "summaries_dir= '/home/mike/Documents/keras_lstm/LSTM_Sentiment/logs/'\n",
    "\n",
    "\n",
    "n_samples= None # Set n_samples=None to use the whole dataset\n",
    "batch_size = 100 # Batch size\n",
    "train_steps = 1000 # Number of training steps\n",
    "hidden_size= 75 # Hidden size of LSTM layer\n",
    "embedding_size = 75 # Size of embeddings layer\n",
    "\n",
    "\n",
    "# random_state = 0 # Random state used for data splitting. Default is 0\n",
    "learning_rate = 0.01\n",
    "test_size = 0.2\n",
    "dropout_keep_prob = 0.5 # 0<dropout_keep_prob<=1. Dropout keep-probability\n",
    "sequence_len = None # Maximum sequence length\n",
    "validate_every = 100 # Step frequency in order to evaluate the model using a validation set'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the summaries\n",
    "summaries_dir = '{0}/{1}'.format(summaries_dir, datetime.datetime.now().strftime('%d_%b_%Y-%H_%M_%S'))\n",
    "train_writer = tf.summary.FileWriter(summaries_dir + '/train')\n",
    "validation_writer = tf.summary.FileWriter(summaries_dir + '/validation')\n",
    "\n",
    "\n",
    "# Prepare the model directory\n",
    "model_name = str(int(time.time()))\n",
    "model_dir = '{0}/{1}'.format('checkpoints', model_name)\n",
    "\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading preprocessed files ...\n",
      "WARNING:tensorflow:From /home/mike/Documents/keras_lstm/LSTM_Sentiment/lstm_network.py:111: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From /home/mike/Documents/keras_lstm/LSTM_Sentiment/lstm_network.py:152: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /home/mike/miniconda3/lib/python3.7/site-packages/tensorflow/python/ops/rnn_cell_impl.py:966: Layer.add_variable (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "WARNING:tensorflow:From /home/mike/miniconda3/lib/python3.7/site-packages/tensorflow/python/ops/rnn_cell_impl.py:970: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/mike/miniconda3/lib/python3.7/site-packages/tensorflow/python/training/rmsprop.py:123: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "1/1000 train loss: 0.7447\n",
      "2/1000 train loss: 0.6992\n",
      "3/1000 train loss: 0.6758\n",
      "4/1000 train loss: 0.7435\n",
      "5/1000 train loss: 0.7208\n",
      "6/1000 train loss: 0.6923\n",
      "7/1000 train loss: 0.6695\n",
      "8/1000 train loss: 0.6809\n",
      "9/1000 train loss: 0.6977\n",
      "10/1000 train loss: 0.7304\n",
      "11/1000 train loss: 0.6857\n",
      "12/1000 train loss: 0.6588\n",
      "13/1000 train loss: 0.7293\n",
      "14/1000 train loss: 0.7016\n",
      "15/1000 train loss: 0.7069\n",
      "16/1000 train loss: 0.7170\n",
      "17/1000 train loss: 0.6740\n",
      "18/1000 train loss: 0.7163\n",
      "19/1000 train loss: 0.7201\n",
      "20/1000 train loss: 0.7090\n",
      "21/1000 train loss: 0.6991\n",
      "22/1000 train loss: 0.6836\n",
      "23/1000 train loss: 0.6982\n",
      "24/1000 train loss: 0.6934\n",
      "25/1000 train loss: 0.6972\n",
      "26/1000 train loss: 0.7066\n",
      "27/1000 train loss: 0.6820\n",
      "28/1000 train loss: 0.6828\n",
      "29/1000 train loss: 0.7001\n",
      "30/1000 train loss: 0.7232\n",
      "31/1000 train loss: 0.7003\n",
      "32/1000 train loss: 0.6471\n",
      "33/1000 train loss: 0.7378\n",
      "34/1000 train loss: 0.7132\n",
      "35/1000 train loss: 0.6813\n",
      "36/1000 train loss: 0.6896\n",
      "37/1000 train loss: 0.7158\n",
      "38/1000 train loss: 0.6658\n",
      "39/1000 train loss: 0.7138\n",
      "40/1000 train loss: 0.6858\n",
      "41/1000 train loss: 0.7030\n",
      "42/1000 train loss: 0.6853\n",
      "43/1000 train loss: 0.6961\n",
      "44/1000 train loss: 0.6881\n",
      "45/1000 train loss: 0.6963\n",
      "46/1000 train loss: 0.6825\n",
      "47/1000 train loss: 0.6728\n",
      "48/1000 train loss: 0.6732\n",
      "49/1000 train loss: 0.6939\n",
      "50/1000 train loss: 0.7196\n",
      "51/1000 train loss: 0.7027\n",
      "52/1000 train loss: 0.6922\n",
      "53/1000 train loss: 0.6901\n",
      "54/1000 train loss: 0.6935\n",
      "55/1000 train loss: 0.6853\n",
      "56/1000 train loss: 0.6956\n",
      "57/1000 train loss: 0.6726\n",
      "58/1000 train loss: 0.6735\n",
      "59/1000 train loss: 0.6873\n",
      "60/1000 train loss: 0.6893\n",
      "61/1000 train loss: 0.7184\n",
      "62/1000 train loss: 0.6862\n",
      "63/1000 train loss: 0.6849\n",
      "64/1000 train loss: 0.6804\n",
      "65/1000 train loss: 0.6807\n",
      "66/1000 train loss: 0.6730\n",
      "67/1000 train loss: 0.6780\n",
      "68/1000 train loss: 0.6846\n",
      "69/1000 train loss: 0.7031\n",
      "70/1000 train loss: 0.6851\n",
      "71/1000 train loss: 0.6759\n",
      "72/1000 train loss: 0.6915\n",
      "73/1000 train loss: 0.6734\n",
      "74/1000 train loss: 0.6831\n",
      "75/1000 train loss: 0.6961\n",
      "76/1000 train loss: 0.6832\n",
      "77/1000 train loss: 0.6823\n",
      "78/1000 train loss: 0.7037\n",
      "79/1000 train loss: 0.6740\n",
      "80/1000 train loss: 0.6952\n",
      "81/1000 train loss: 0.6823\n",
      "82/1000 train loss: 0.6900\n",
      "83/1000 train loss: 0.7057\n",
      "84/1000 train loss: 0.6700\n",
      "85/1000 train loss: 0.6944\n",
      "86/1000 train loss: 0.6873\n",
      "87/1000 train loss: 0.6770\n",
      "88/1000 train loss: 0.6801\n",
      "89/1000 train loss: 0.6899\n",
      "90/1000 train loss: 0.6877\n",
      "91/1000 train loss: 0.6893\n",
      "92/1000 train loss: 0.6821\n",
      "93/1000 train loss: 0.6871\n",
      "94/1000 train loss: 0.7016\n",
      "95/1000 train loss: 0.6794\n",
      "96/1000 train loss: 0.6862\n",
      "97/1000 train loss: 0.6767\n",
      "98/1000 train loss: 0.6884\n",
      "99/1000 train loss: 0.6769\n",
      "100/1000 train loss: 0.6912\n",
      "   validation loss: 0.6867 (accuracy 0.5300)\n",
      "101/1000 train loss: 0.6759\n",
      "102/1000 train loss: 0.6806\n",
      "103/1000 train loss: 0.6917\n",
      "104/1000 train loss: 0.6878\n",
      "105/1000 train loss: 0.6801\n",
      "106/1000 train loss: 0.7024\n",
      "107/1000 train loss: 0.6765\n",
      "108/1000 train loss: 0.6689\n",
      "109/1000 train loss: 0.6872\n",
      "110/1000 train loss: 0.6766\n",
      "111/1000 train loss: 0.6823\n",
      "112/1000 train loss: 0.6757\n",
      "113/1000 train loss: 0.6818\n",
      "114/1000 train loss: 0.6777\n",
      "115/1000 train loss: 0.6716\n",
      "116/1000 train loss: 0.6994\n",
      "117/1000 train loss: 0.6892\n",
      "118/1000 train loss: 0.6783\n",
      "119/1000 train loss: 0.7030\n",
      "120/1000 train loss: 0.6702\n",
      "121/1000 train loss: 0.6868\n",
      "122/1000 train loss: 0.6782\n",
      "123/1000 train loss: 0.7072\n",
      "124/1000 train loss: 0.6650\n",
      "125/1000 train loss: 0.6542\n",
      "126/1000 train loss: 0.6875\n",
      "127/1000 train loss: 0.6640\n",
      "128/1000 train loss: 0.6529\n",
      "129/1000 train loss: 0.6679\n",
      "130/1000 train loss: 0.6854\n",
      "131/1000 train loss: 0.6580\n",
      "132/1000 train loss: 0.6609\n",
      "133/1000 train loss: 0.6341\n",
      "134/1000 train loss: 0.6034\n",
      "135/1000 train loss: 0.6230\n",
      "136/1000 train loss: 0.6465\n",
      "137/1000 train loss: 0.5739\n",
      "138/1000 train loss: 0.5616\n",
      "139/1000 train loss: 0.5920\n",
      "140/1000 train loss: 0.5862\n",
      "141/1000 train loss: 0.5412\n",
      "142/1000 train loss: 0.4976\n",
      "143/1000 train loss: 0.4845\n",
      "144/1000 train loss: 0.5520\n",
      "145/1000 train loss: 0.4921\n",
      "146/1000 train loss: 0.4436\n",
      "147/1000 train loss: 0.4305\n",
      "148/1000 train loss: 0.3864\n",
      "149/1000 train loss: 0.3400\n",
      "150/1000 train loss: 0.3020\n",
      "151/1000 train loss: 0.3217\n",
      "152/1000 train loss: 0.3664\n",
      "153/1000 train loss: 0.2713\n",
      "154/1000 train loss: 0.3196\n",
      "155/1000 train loss: 0.2991\n",
      "156/1000 train loss: 0.4274\n",
      "157/1000 train loss: 0.3168\n",
      "158/1000 train loss: 0.3419\n",
      "159/1000 train loss: 0.3949\n",
      "160/1000 train loss: 0.2962\n",
      "161/1000 train loss: 0.2383\n",
      "162/1000 train loss: 0.3207\n",
      "163/1000 train loss: 0.3226\n",
      "164/1000 train loss: 0.2118\n",
      "165/1000 train loss: 0.2425\n",
      "166/1000 train loss: 0.2288\n",
      "167/1000 train loss: 0.2229\n",
      "168/1000 train loss: 0.2215\n",
      "169/1000 train loss: 0.1804\n",
      "170/1000 train loss: 0.2051\n",
      "171/1000 train loss: 0.2199\n",
      "172/1000 train loss: 0.2001\n",
      "173/1000 train loss: 0.2291\n",
      "174/1000 train loss: 0.1631\n",
      "175/1000 train loss: 0.1733\n",
      "176/1000 train loss: 0.1843\n",
      "177/1000 train loss: 0.1537\n",
      "178/1000 train loss: 0.1464\n",
      "179/1000 train loss: 0.1108\n",
      "180/1000 train loss: 0.2341\n",
      "181/1000 train loss: 0.1731\n",
      "182/1000 train loss: 0.1227\n",
      "183/1000 train loss: 0.1309\n",
      "184/1000 train loss: 0.1753\n",
      "185/1000 train loss: 0.1099\n",
      "186/1000 train loss: 0.1562\n",
      "187/1000 train loss: 0.1574\n",
      "188/1000 train loss: 0.1145\n",
      "189/1000 train loss: 0.1003\n",
      "190/1000 train loss: 0.1333\n",
      "191/1000 train loss: 0.1170\n",
      "192/1000 train loss: 0.0778\n",
      "193/1000 train loss: 0.1408\n",
      "194/1000 train loss: 0.1020\n",
      "195/1000 train loss: 0.1181\n",
      "196/1000 train loss: 0.0508\n",
      "197/1000 train loss: 0.1125\n",
      "198/1000 train loss: 0.1474\n",
      "199/1000 train loss: 0.1000\n",
      "200/1000 train loss: 0.0725\n",
      "   validation loss: 0.0847 (accuracy 0.9700)\n",
      "201/1000 train loss: 0.0894\n",
      "202/1000 train loss: 0.0717\n",
      "203/1000 train loss: 0.0832\n",
      "204/1000 train loss: 0.1007\n",
      "205/1000 train loss: 0.0630\n",
      "206/1000 train loss: 0.0593\n",
      "207/1000 train loss: 0.0619\n",
      "208/1000 train loss: 0.0964\n",
      "209/1000 train loss: 0.0961\n",
      "210/1000 train loss: 0.0519\n",
      "211/1000 train loss: 0.0892\n",
      "212/1000 train loss: 0.0875\n",
      "213/1000 train loss: 0.0822\n",
      "214/1000 train loss: 0.0543\n",
      "215/1000 train loss: 0.1059\n",
      "216/1000 train loss: 0.0662\n",
      "217/1000 train loss: 0.0826\n",
      "218/1000 train loss: 0.0837\n",
      "219/1000 train loss: 0.1464\n",
      "220/1000 train loss: 0.0734\n",
      "221/1000 train loss: 0.0904\n",
      "222/1000 train loss: 0.0315\n",
      "223/1000 train loss: 0.0589\n",
      "224/1000 train loss: 0.0486\n",
      "225/1000 train loss: 0.0587\n",
      "226/1000 train loss: 0.0547\n",
      "227/1000 train loss: 0.0696\n",
      "228/1000 train loss: 0.1245\n",
      "229/1000 train loss: 0.0677\n",
      "230/1000 train loss: 0.0508\n",
      "231/1000 train loss: 0.0464\n",
      "232/1000 train loss: 0.0536\n",
      "233/1000 train loss: 0.0695\n",
      "234/1000 train loss: 0.0231\n",
      "235/1000 train loss: 0.0869\n",
      "236/1000 train loss: 0.1524\n",
      "237/1000 train loss: 0.0733\n",
      "238/1000 train loss: 0.0418\n",
      "239/1000 train loss: 0.0566\n",
      "240/1000 train loss: 0.0699\n",
      "241/1000 train loss: 0.0484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/1000 train loss: 0.0483\n",
      "243/1000 train loss: 0.0253\n",
      "244/1000 train loss: 0.0646\n",
      "245/1000 train loss: 0.0200\n",
      "246/1000 train loss: 0.0495\n",
      "247/1000 train loss: 0.0308\n",
      "248/1000 train loss: 0.0565\n",
      "249/1000 train loss: 0.0565\n",
      "250/1000 train loss: 0.0639\n",
      "251/1000 train loss: 0.0516\n",
      "252/1000 train loss: 0.0114\n",
      "253/1000 train loss: 0.0250\n",
      "254/1000 train loss: 0.0566\n",
      "255/1000 train loss: 0.0477\n",
      "256/1000 train loss: 0.0604\n",
      "257/1000 train loss: 0.1126\n",
      "258/1000 train loss: 0.0504\n",
      "259/1000 train loss: 0.0205\n",
      "260/1000 train loss: 0.0765\n",
      "261/1000 train loss: 0.0351\n",
      "262/1000 train loss: 0.0839\n",
      "263/1000 train loss: 0.0363\n",
      "264/1000 train loss: 0.0226\n",
      "265/1000 train loss: 0.0426\n",
      "266/1000 train loss: 0.0241\n",
      "267/1000 train loss: 0.0402\n",
      "268/1000 train loss: 0.0277\n",
      "269/1000 train loss: 0.0238\n",
      "270/1000 train loss: 0.0302\n",
      "271/1000 train loss: 0.0281\n",
      "272/1000 train loss: 0.0227\n",
      "273/1000 train loss: 0.0240\n",
      "274/1000 train loss: 0.0616\n",
      "275/1000 train loss: 0.0168\n",
      "276/1000 train loss: 0.0173\n",
      "277/1000 train loss: 0.0224\n",
      "278/1000 train loss: 0.0131\n",
      "279/1000 train loss: 0.0245\n",
      "280/1000 train loss: 0.0411\n",
      "281/1000 train loss: 0.0234\n",
      "282/1000 train loss: 0.0297\n",
      "283/1000 train loss: 0.0321\n",
      "284/1000 train loss: 0.0334\n",
      "285/1000 train loss: 0.0305\n",
      "286/1000 train loss: 0.0570\n",
      "287/1000 train loss: 0.0116\n",
      "288/1000 train loss: 0.0245\n",
      "289/1000 train loss: 0.0252\n",
      "290/1000 train loss: 0.0183\n",
      "291/1000 train loss: 0.0106\n",
      "292/1000 train loss: 0.0167\n",
      "293/1000 train loss: 0.0323\n",
      "294/1000 train loss: 0.0827\n",
      "295/1000 train loss: 0.0277\n",
      "296/1000 train loss: 0.0091\n",
      "297/1000 train loss: 0.0262\n",
      "298/1000 train loss: 0.0237\n",
      "299/1000 train loss: 0.0137\n",
      "300/1000 train loss: 0.0339\n",
      "   validation loss: 0.0570 (accuracy 0.9700)\n",
      "301/1000 train loss: 0.0137\n",
      "302/1000 train loss: 0.0184\n",
      "303/1000 train loss: 0.0437\n",
      "304/1000 train loss: 0.0311\n",
      "305/1000 train loss: 0.0138\n",
      "306/1000 train loss: 0.0250\n",
      "307/1000 train loss: 0.0158\n",
      "308/1000 train loss: 0.0102\n",
      "309/1000 train loss: 0.0180\n",
      "310/1000 train loss: 0.0479\n",
      "311/1000 train loss: 0.0819\n",
      "312/1000 train loss: 0.0232\n",
      "313/1000 train loss: 0.0101\n",
      "314/1000 train loss: 0.0059\n",
      "315/1000 train loss: 0.0103\n",
      "316/1000 train loss: 0.0106\n",
      "317/1000 train loss: 0.0161\n",
      "318/1000 train loss: 0.0293\n",
      "319/1000 train loss: 0.0030\n",
      "320/1000 train loss: 0.0084\n",
      "321/1000 train loss: 0.0034\n",
      "322/1000 train loss: 0.0118\n",
      "323/1000 train loss: 0.0111\n",
      "324/1000 train loss: 0.0099\n",
      "325/1000 train loss: 0.0086\n",
      "326/1000 train loss: 0.0039\n",
      "327/1000 train loss: 0.0049\n",
      "328/1000 train loss: 0.0080\n",
      "329/1000 train loss: 0.0097\n",
      "330/1000 train loss: 0.0422\n",
      "331/1000 train loss: 0.0083\n",
      "332/1000 train loss: 0.0118\n",
      "333/1000 train loss: 0.0109\n",
      "334/1000 train loss: 0.0142\n",
      "335/1000 train loss: 0.0107\n",
      "336/1000 train loss: 0.0022\n",
      "337/1000 train loss: 0.0017\n",
      "338/1000 train loss: 0.0163\n",
      "339/1000 train loss: 0.0058\n",
      "340/1000 train loss: 0.0199\n",
      "341/1000 train loss: 0.0168\n",
      "342/1000 train loss: 0.0082\n",
      "343/1000 train loss: 0.0052\n",
      "344/1000 train loss: 0.0117\n",
      "345/1000 train loss: 0.0120\n",
      "346/1000 train loss: 0.0283\n",
      "347/1000 train loss: 0.0164\n",
      "348/1000 train loss: 0.0054\n",
      "349/1000 train loss: 0.0078\n",
      "350/1000 train loss: 0.0141\n",
      "351/1000 train loss: 0.0090\n",
      "352/1000 train loss: 0.0071\n",
      "353/1000 train loss: 0.0052\n",
      "354/1000 train loss: 0.0086\n",
      "355/1000 train loss: 0.0060\n",
      "356/1000 train loss: 0.0226\n",
      "357/1000 train loss: 0.0367\n",
      "358/1000 train loss: 0.0438\n",
      "359/1000 train loss: 0.0334\n",
      "360/1000 train loss: 0.0051\n",
      "361/1000 train loss: 0.0021\n",
      "362/1000 train loss: 0.0097\n",
      "363/1000 train loss: 0.0203\n",
      "364/1000 train loss: 0.0146\n",
      "365/1000 train loss: 0.0100\n",
      "366/1000 train loss: 0.0025\n",
      "367/1000 train loss: 0.0036\n",
      "368/1000 train loss: 0.0087\n",
      "369/1000 train loss: 0.0031\n",
      "370/1000 train loss: 0.0075\n",
      "371/1000 train loss: 0.0046\n",
      "372/1000 train loss: 0.0060\n",
      "373/1000 train loss: 0.0014\n",
      "374/1000 train loss: 0.0100\n",
      "375/1000 train loss: 0.0189\n",
      "376/1000 train loss: 0.0114\n",
      "377/1000 train loss: 0.0066\n",
      "378/1000 train loss: 0.0049\n",
      "379/1000 train loss: 0.0054\n",
      "380/1000 train loss: 0.0096\n",
      "381/1000 train loss: 0.0018\n",
      "382/1000 train loss: 0.0045\n",
      "383/1000 train loss: 0.0033\n",
      "384/1000 train loss: 0.0031\n",
      "385/1000 train loss: 0.0036\n",
      "386/1000 train loss: 0.0038\n",
      "387/1000 train loss: 0.0006\n",
      "388/1000 train loss: 0.0050\n",
      "389/1000 train loss: 0.0018\n",
      "390/1000 train loss: 0.0032\n",
      "391/1000 train loss: 0.0014\n",
      "392/1000 train loss: 0.0067\n",
      "393/1000 train loss: 0.0025\n",
      "394/1000 train loss: 0.0048\n",
      "395/1000 train loss: 0.0013\n",
      "396/1000 train loss: 0.0026\n",
      "397/1000 train loss: 0.0022\n",
      "398/1000 train loss: 0.0038\n",
      "399/1000 train loss: 0.0118\n",
      "400/1000 train loss: 0.0014\n",
      "   validation loss: 0.0727 (accuracy 0.9700)\n",
      "401/1000 train loss: 0.0014\n",
      "402/1000 train loss: 0.0027\n",
      "403/1000 train loss: 0.0343\n",
      "404/1000 train loss: 0.0801\n",
      "405/1000 train loss: 0.0248\n",
      "406/1000 train loss: 0.0178\n",
      "407/1000 train loss: 0.0066\n",
      "408/1000 train loss: 0.0028\n",
      "409/1000 train loss: 0.0029\n",
      "410/1000 train loss: 0.0044\n",
      "411/1000 train loss: 0.0022\n",
      "412/1000 train loss: 0.0038\n",
      "413/1000 train loss: 0.0067\n",
      "414/1000 train loss: 0.0039\n",
      "415/1000 train loss: 0.0135\n",
      "416/1000 train loss: 0.0015\n",
      "417/1000 train loss: 0.0046\n",
      "418/1000 train loss: 0.0206\n",
      "419/1000 train loss: 0.0209\n",
      "420/1000 train loss: 0.0037\n",
      "421/1000 train loss: 0.0059\n",
      "422/1000 train loss: 0.0033\n",
      "423/1000 train loss: 0.0022\n",
      "424/1000 train loss: 0.0019\n",
      "425/1000 train loss: 0.0276\n",
      "426/1000 train loss: 0.0247\n",
      "427/1000 train loss: 0.0016\n",
      "428/1000 train loss: 0.0026\n",
      "429/1000 train loss: 0.0026\n",
      "430/1000 train loss: 0.0010\n",
      "431/1000 train loss: 0.0036\n",
      "432/1000 train loss: 0.0056\n",
      "433/1000 train loss: 0.0025\n",
      "434/1000 train loss: 0.0010\n",
      "435/1000 train loss: 0.0010\n",
      "436/1000 train loss: 0.0038\n",
      "437/1000 train loss: 0.0040\n",
      "438/1000 train loss: 0.0010\n",
      "439/1000 train loss: 0.0011\n",
      "440/1000 train loss: 0.0022\n",
      "441/1000 train loss: 0.0019\n",
      "442/1000 train loss: 0.0077\n",
      "443/1000 train loss: 0.0034\n",
      "444/1000 train loss: 0.0149\n",
      "445/1000 train loss: 0.0021\n",
      "446/1000 train loss: 0.0026\n",
      "447/1000 train loss: 0.0018\n",
      "448/1000 train loss: 0.0021\n",
      "449/1000 train loss: 0.0016\n",
      "450/1000 train loss: 0.0009\n",
      "451/1000 train loss: 0.0013\n",
      "452/1000 train loss: 0.0026\n",
      "453/1000 train loss: 0.0013\n",
      "454/1000 train loss: 0.0013\n",
      "455/1000 train loss: 0.0062\n",
      "456/1000 train loss: 0.0011\n",
      "457/1000 train loss: 0.0056\n",
      "458/1000 train loss: 0.0016\n",
      "459/1000 train loss: 0.0006\n",
      "460/1000 train loss: 0.0018\n",
      "461/1000 train loss: 0.0016\n",
      "462/1000 train loss: 0.0003\n",
      "463/1000 train loss: 0.0360\n",
      "464/1000 train loss: 0.0485\n",
      "465/1000 train loss: 0.0097\n",
      "466/1000 train loss: 0.0030\n",
      "467/1000 train loss: 0.0017\n",
      "468/1000 train loss: 0.0088\n",
      "469/1000 train loss: 0.0003\n",
      "470/1000 train loss: 0.0008\n",
      "471/1000 train loss: 0.0018\n",
      "472/1000 train loss: 0.0036\n",
      "473/1000 train loss: 0.0028\n",
      "474/1000 train loss: 0.0029\n",
      "475/1000 train loss: 0.0011\n",
      "476/1000 train loss: 0.0074\n",
      "477/1000 train loss: 0.0013\n",
      "478/1000 train loss: 0.0005\n",
      "479/1000 train loss: 0.0018\n",
      "480/1000 train loss: 0.0010\n",
      "481/1000 train loss: 0.0016\n",
      "482/1000 train loss: 0.0018\n",
      "483/1000 train loss: 0.0008\n",
      "484/1000 train loss: 0.0013\n",
      "485/1000 train loss: 0.0059\n",
      "486/1000 train loss: 0.0003\n",
      "487/1000 train loss: 0.0015\n",
      "488/1000 train loss: 0.0013\n",
      "489/1000 train loss: 0.0012\n",
      "490/1000 train loss: 0.0015\n",
      "491/1000 train loss: 0.0011\n",
      "492/1000 train loss: 0.0004\n",
      "493/1000 train loss: 0.0040\n",
      "494/1000 train loss: 0.0035\n",
      "495/1000 train loss: 0.0011\n",
      "496/1000 train loss: 0.0004\n",
      "497/1000 train loss: 0.0025\n",
      "498/1000 train loss: 0.0010\n",
      "499/1000 train loss: 0.0017\n",
      "500/1000 train loss: 0.0004\n",
      "   validation loss: 0.0652 (accuracy 0.9700)\n",
      "501/1000 train loss: 0.0001\n",
      "502/1000 train loss: 0.0009\n",
      "503/1000 train loss: 0.0009\n",
      "504/1000 train loss: 0.0011\n",
      "505/1000 train loss: 0.0013\n",
      "506/1000 train loss: 0.0023\n",
      "507/1000 train loss: 0.0012\n",
      "508/1000 train loss: 0.0014\n",
      "509/1000 train loss: 0.0060\n",
      "510/1000 train loss: 0.0014\n",
      "511/1000 train loss: 0.0010\n",
      "512/1000 train loss: 0.0003\n",
      "513/1000 train loss: 0.0043\n",
      "514/1000 train loss: 0.0015\n",
      "515/1000 train loss: 0.0005\n",
      "516/1000 train loss: 0.0003\n",
      "517/1000 train loss: 0.0002\n",
      "518/1000 train loss: 0.0017\n",
      "519/1000 train loss: 0.0061\n",
      "520/1000 train loss: 0.0012\n",
      "521/1000 train loss: 0.0008\n",
      "522/1000 train loss: 0.0005\n",
      "523/1000 train loss: 0.0005\n",
      "524/1000 train loss: 0.0014\n",
      "525/1000 train loss: 0.0003\n",
      "526/1000 train loss: 0.0008\n",
      "527/1000 train loss: 0.0002\n",
      "528/1000 train loss: 0.0008\n",
      "529/1000 train loss: 0.0009\n",
      "530/1000 train loss: 0.0022\n",
      "531/1000 train loss: 0.0005\n",
      "532/1000 train loss: 0.0004\n",
      "533/1000 train loss: 0.0009\n",
      "534/1000 train loss: 0.0003\n",
      "535/1000 train loss: 0.0016\n",
      "536/1000 train loss: 0.0004\n",
      "537/1000 train loss: 0.0004\n",
      "538/1000 train loss: 0.0007\n",
      "539/1000 train loss: 0.0003\n",
      "540/1000 train loss: 0.0004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "541/1000 train loss: 0.0003\n",
      "542/1000 train loss: 0.0006\n",
      "543/1000 train loss: 0.0002\n",
      "544/1000 train loss: 0.0053\n",
      "545/1000 train loss: 0.1541\n",
      "546/1000 train loss: 0.0347\n",
      "547/1000 train loss: 0.0059\n",
      "548/1000 train loss: 0.0014\n",
      "549/1000 train loss: 0.0028\n",
      "550/1000 train loss: 0.0005\n",
      "551/1000 train loss: 0.0009\n",
      "552/1000 train loss: 0.0009\n",
      "553/1000 train loss: 0.0007\n",
      "554/1000 train loss: 0.0044\n",
      "555/1000 train loss: 0.0002\n",
      "556/1000 train loss: 0.0007\n",
      "557/1000 train loss: 0.0004\n",
      "558/1000 train loss: 0.0004\n",
      "559/1000 train loss: 0.0020\n",
      "560/1000 train loss: 0.0013\n",
      "561/1000 train loss: 0.0001\n",
      "562/1000 train loss: 0.0006\n",
      "563/1000 train loss: 0.0006\n",
      "564/1000 train loss: 0.0003\n",
      "565/1000 train loss: 0.0013\n",
      "566/1000 train loss: 0.0009\n",
      "567/1000 train loss: 0.0003\n",
      "568/1000 train loss: 0.0013\n",
      "569/1000 train loss: 0.0056\n",
      "570/1000 train loss: 0.0002\n",
      "571/1000 train loss: 0.0002\n",
      "572/1000 train loss: 0.0004\n",
      "573/1000 train loss: 0.0017\n",
      "574/1000 train loss: 0.0003\n",
      "575/1000 train loss: 0.0015\n",
      "576/1000 train loss: 0.0003\n",
      "577/1000 train loss: 0.0002\n",
      "578/1000 train loss: 0.0009\n",
      "579/1000 train loss: 0.0001\n",
      "580/1000 train loss: 0.0002\n",
      "581/1000 train loss: 0.0003\n",
      "582/1000 train loss: 0.0007\n",
      "583/1000 train loss: 0.0004\n",
      "584/1000 train loss: 0.0006\n",
      "585/1000 train loss: 0.0002\n",
      "586/1000 train loss: 0.0008\n",
      "587/1000 train loss: 0.0004\n",
      "588/1000 train loss: 0.0001\n",
      "589/1000 train loss: 0.0003\n",
      "590/1000 train loss: 0.0005\n",
      "591/1000 train loss: 0.0001\n",
      "592/1000 train loss: 0.0002\n",
      "593/1000 train loss: 0.0003\n",
      "594/1000 train loss: 0.0005\n",
      "595/1000 train loss: 0.0020\n",
      "596/1000 train loss: 0.0008\n",
      "597/1000 train loss: 0.0001\n",
      "598/1000 train loss: 0.0008\n",
      "599/1000 train loss: 0.0014\n",
      "600/1000 train loss: 0.0395\n",
      "   validation loss: 0.1540 (accuracy 0.9500)\n",
      "601/1000 train loss: 0.0082\n",
      "602/1000 train loss: 0.0008\n",
      "603/1000 train loss: 0.0014\n",
      "604/1000 train loss: 0.0004\n",
      "605/1000 train loss: 0.0004\n",
      "606/1000 train loss: 0.0035\n",
      "607/1000 train loss: 0.0002\n",
      "608/1000 train loss: 0.0004\n",
      "609/1000 train loss: 0.0007\n",
      "610/1000 train loss: 0.0003\n",
      "611/1000 train loss: 0.0001\n",
      "612/1000 train loss: 0.0001\n",
      "613/1000 train loss: 0.0001\n",
      "614/1000 train loss: 0.0015\n",
      "615/1000 train loss: 0.0010\n",
      "616/1000 train loss: 0.0001\n",
      "617/1000 train loss: 0.0004\n",
      "618/1000 train loss: 0.0010\n",
      "619/1000 train loss: 0.0008\n",
      "620/1000 train loss: 0.0002\n",
      "621/1000 train loss: 0.0003\n",
      "622/1000 train loss: 0.0003\n",
      "623/1000 train loss: 0.0004\n",
      "624/1000 train loss: 0.0015\n",
      "625/1000 train loss: 0.0003\n",
      "626/1000 train loss: 0.0011\n",
      "627/1000 train loss: 0.0001\n",
      "628/1000 train loss: 0.0004\n",
      "629/1000 train loss: 0.0268\n",
      "630/1000 train loss: 0.0007\n",
      "631/1000 train loss: 0.0004\n",
      "632/1000 train loss: 0.0002\n",
      "633/1000 train loss: 0.0003\n",
      "634/1000 train loss: 0.0002\n",
      "635/1000 train loss: 0.0002\n",
      "636/1000 train loss: 0.0006\n",
      "637/1000 train loss: 0.0006\n",
      "638/1000 train loss: 0.0130\n",
      "639/1000 train loss: 0.0009\n",
      "640/1000 train loss: 0.0062\n",
      "641/1000 train loss: 0.0004\n",
      "642/1000 train loss: 0.0001\n",
      "643/1000 train loss: 0.0001\n",
      "644/1000 train loss: 0.0023\n",
      "645/1000 train loss: 0.0002\n",
      "646/1000 train loss: 0.0004\n",
      "647/1000 train loss: 0.0002\n",
      "648/1000 train loss: 0.0001\n",
      "649/1000 train loss: 0.0000\n",
      "650/1000 train loss: 0.0005\n",
      "651/1000 train loss: 0.0011\n",
      "652/1000 train loss: 0.0003\n",
      "653/1000 train loss: 0.0004\n",
      "654/1000 train loss: 0.0029\n",
      "655/1000 train loss: 0.0009\n",
      "656/1000 train loss: 0.0011\n",
      "657/1000 train loss: 0.0032\n",
      "658/1000 train loss: 0.0032\n",
      "659/1000 train loss: 0.0001\n",
      "660/1000 train loss: 0.0006\n",
      "661/1000 train loss: 0.0002\n",
      "662/1000 train loss: 0.0001\n",
      "663/1000 train loss: 0.0001\n",
      "664/1000 train loss: 0.0005\n",
      "665/1000 train loss: 0.0007\n",
      "666/1000 train loss: 0.0005\n",
      "667/1000 train loss: 0.0003\n",
      "668/1000 train loss: 0.0001\n",
      "669/1000 train loss: 0.0024\n",
      "670/1000 train loss: 0.0002\n",
      "671/1000 train loss: 0.0001\n",
      "672/1000 train loss: 0.0001\n",
      "673/1000 train loss: 0.0002\n",
      "674/1000 train loss: 0.0001\n",
      "675/1000 train loss: 0.0001\n",
      "676/1000 train loss: 0.0001\n",
      "677/1000 train loss: 0.0001\n",
      "678/1000 train loss: 0.0007\n",
      "679/1000 train loss: 0.0010\n",
      "680/1000 train loss: 0.0004\n",
      "681/1000 train loss: 0.0000\n",
      "682/1000 train loss: 0.0001\n",
      "683/1000 train loss: 0.0001\n",
      "684/1000 train loss: 0.0003\n",
      "685/1000 train loss: 0.0007\n",
      "686/1000 train loss: 0.0002\n",
      "687/1000 train loss: 0.0002\n",
      "688/1000 train loss: 0.0001\n",
      "689/1000 train loss: 0.0015\n",
      "690/1000 train loss: 0.0007\n",
      "691/1000 train loss: 0.0001\n",
      "692/1000 train loss: 0.0001\n",
      "693/1000 train loss: 0.0000\n",
      "694/1000 train loss: 0.0004\n",
      "695/1000 train loss: 0.0001\n",
      "696/1000 train loss: 0.0002\n",
      "697/1000 train loss: 0.0001\n",
      "698/1000 train loss: 0.0074\n",
      "699/1000 train loss: 0.0008\n",
      "700/1000 train loss: 0.0001\n",
      "   validation loss: 0.1153 (accuracy 0.9700)\n",
      "701/1000 train loss: 0.0015\n",
      "702/1000 train loss: 0.0004\n",
      "703/1000 train loss: 0.0001\n",
      "704/1000 train loss: 0.0003\n",
      "705/1000 train loss: 0.0002\n",
      "706/1000 train loss: 0.0001\n",
      "707/1000 train loss: 0.0000\n",
      "708/1000 train loss: 0.0001\n",
      "709/1000 train loss: 0.0000\n",
      "710/1000 train loss: 0.0003\n",
      "711/1000 train loss: 0.0001\n",
      "712/1000 train loss: 0.0001\n",
      "713/1000 train loss: 0.0001\n",
      "714/1000 train loss: 0.0001\n",
      "715/1000 train loss: 0.0004\n",
      "716/1000 train loss: 0.0001\n",
      "717/1000 train loss: 0.0005\n",
      "718/1000 train loss: 0.0001\n",
      "719/1000 train loss: 0.0015\n",
      "720/1000 train loss: 0.0009\n",
      "721/1000 train loss: 0.0001\n",
      "722/1000 train loss: 0.0000\n",
      "723/1000 train loss: 0.0001\n",
      "724/1000 train loss: 0.0007\n",
      "725/1000 train loss: 0.0015\n",
      "726/1000 train loss: 0.0028\n",
      "727/1000 train loss: 0.0001\n",
      "728/1000 train loss: 0.0008\n",
      "729/1000 train loss: 0.0003\n",
      "730/1000 train loss: 0.0002\n",
      "731/1000 train loss: 0.0001\n",
      "732/1000 train loss: 0.0005\n",
      "733/1000 train loss: 0.0001\n",
      "734/1000 train loss: 0.0017\n",
      "735/1000 train loss: 0.0000\n",
      "736/1000 train loss: 0.0007\n",
      "737/1000 train loss: 0.0001\n",
      "738/1000 train loss: 0.0002\n",
      "739/1000 train loss: 0.0001\n",
      "740/1000 train loss: 0.0017\n",
      "741/1000 train loss: 0.0007\n",
      "742/1000 train loss: 0.0003\n",
      "743/1000 train loss: 0.0001\n",
      "744/1000 train loss: 0.0001\n",
      "745/1000 train loss: 0.0002\n",
      "746/1000 train loss: 0.0002\n",
      "747/1000 train loss: 0.0004\n",
      "748/1000 train loss: 0.0001\n",
      "749/1000 train loss: 0.0003\n",
      "750/1000 train loss: 0.0000\n",
      "751/1000 train loss: 0.0003\n",
      "752/1000 train loss: 0.0001\n",
      "753/1000 train loss: 0.0003\n",
      "754/1000 train loss: 0.0000\n",
      "755/1000 train loss: 0.0000\n",
      "756/1000 train loss: 0.0001\n",
      "757/1000 train loss: 0.0009\n",
      "758/1000 train loss: 0.0000\n",
      "759/1000 train loss: 0.0007\n",
      "760/1000 train loss: 0.0001\n",
      "761/1000 train loss: 0.0001\n",
      "762/1000 train loss: 0.0001\n",
      "763/1000 train loss: 0.0000\n",
      "764/1000 train loss: 0.0002\n",
      "765/1000 train loss: 0.0004\n",
      "766/1000 train loss: 0.0001\n",
      "767/1000 train loss: 0.0005\n",
      "768/1000 train loss: 0.0162\n",
      "769/1000 train loss: 0.0074\n",
      "770/1000 train loss: 0.0022\n",
      "771/1000 train loss: 0.0001\n",
      "772/1000 train loss: 0.0001\n",
      "773/1000 train loss: 0.0002\n",
      "774/1000 train loss: 0.0001\n",
      "775/1000 train loss: 0.0001\n",
      "776/1000 train loss: 0.0000\n",
      "777/1000 train loss: 0.0004\n",
      "778/1000 train loss: 0.0002\n",
      "779/1000 train loss: 0.0000\n",
      "780/1000 train loss: 0.0014\n",
      "781/1000 train loss: 0.0000\n",
      "782/1000 train loss: 0.0001\n",
      "783/1000 train loss: 0.0000\n",
      "784/1000 train loss: 0.0012\n",
      "785/1000 train loss: 0.0000\n",
      "786/1000 train loss: 0.0000\n",
      "787/1000 train loss: 0.0001\n",
      "788/1000 train loss: 0.0004\n",
      "789/1000 train loss: 0.0003\n",
      "790/1000 train loss: 0.0007\n",
      "791/1000 train loss: 0.0000\n",
      "792/1000 train loss: 0.0000\n",
      "793/1000 train loss: 0.0001\n",
      "794/1000 train loss: 0.0001\n",
      "795/1000 train loss: 0.0001\n",
      "796/1000 train loss: 0.0001\n",
      "797/1000 train loss: 0.0001\n",
      "798/1000 train loss: 0.0002\n",
      "799/1000 train loss: 0.0000\n",
      "800/1000 train loss: 0.0000\n",
      "   validation loss: 0.1118 (accuracy 0.9700)\n",
      "801/1000 train loss: 0.0000\n",
      "802/1000 train loss: 0.0000\n",
      "803/1000 train loss: 0.0000\n",
      "804/1000 train loss: 0.0000\n",
      "805/1000 train loss: 0.0021\n",
      "806/1000 train loss: 0.0001\n",
      "807/1000 train loss: 0.0003\n",
      "808/1000 train loss: 0.0000\n",
      "809/1000 train loss: 0.0002\n",
      "810/1000 train loss: 0.0001\n",
      "811/1000 train loss: 0.0001\n",
      "812/1000 train loss: 0.0001\n",
      "813/1000 train loss: 0.0000\n",
      "814/1000 train loss: 0.0001\n",
      "815/1000 train loss: 0.0000\n",
      "816/1000 train loss: 0.0001\n",
      "817/1000 train loss: 0.0002\n",
      "818/1000 train loss: 0.0000\n",
      "819/1000 train loss: 0.0000\n",
      "820/1000 train loss: 0.0000\n",
      "821/1000 train loss: 0.0000\n",
      "822/1000 train loss: 0.0000\n",
      "823/1000 train loss: 0.0000\n",
      "824/1000 train loss: 0.0000\n",
      "825/1000 train loss: 0.0000\n",
      "826/1000 train loss: 0.0001\n",
      "827/1000 train loss: 0.0001\n",
      "828/1000 train loss: 0.0001\n",
      "829/1000 train loss: 0.0001\n",
      "830/1000 train loss: 0.0000\n",
      "831/1000 train loss: 0.0001\n",
      "832/1000 train loss: 0.0001\n",
      "833/1000 train loss: 0.0000\n",
      "834/1000 train loss: 0.0000\n",
      "835/1000 train loss: 0.0000\n",
      "836/1000 train loss: 0.0000\n",
      "837/1000 train loss: 0.0000\n",
      "838/1000 train loss: 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "839/1000 train loss: 0.0007\n",
      "840/1000 train loss: 0.0007\n",
      "841/1000 train loss: 0.0000\n",
      "842/1000 train loss: 0.0001\n",
      "843/1000 train loss: 0.0000\n",
      "844/1000 train loss: 0.0000\n",
      "845/1000 train loss: 0.0003\n",
      "846/1000 train loss: 0.0007\n",
      "847/1000 train loss: 0.0002\n",
      "848/1000 train loss: 0.0000\n",
      "849/1000 train loss: 0.0000\n",
      "850/1000 train loss: 0.0001\n",
      "851/1000 train loss: 0.0000\n",
      "852/1000 train loss: 0.0000\n",
      "853/1000 train loss: 0.0001\n",
      "854/1000 train loss: 0.0000\n",
      "855/1000 train loss: 0.0000\n",
      "856/1000 train loss: 0.0001\n",
      "857/1000 train loss: 0.0000\n",
      "858/1000 train loss: 0.0000\n",
      "859/1000 train loss: 0.0004\n",
      "860/1000 train loss: 0.0008\n",
      "861/1000 train loss: 0.0001\n",
      "862/1000 train loss: 0.0000\n",
      "863/1000 train loss: 0.0000\n",
      "864/1000 train loss: 0.0002\n",
      "865/1000 train loss: 0.0001\n",
      "866/1000 train loss: 0.0000\n",
      "867/1000 train loss: 0.0001\n",
      "868/1000 train loss: 0.0000\n",
      "869/1000 train loss: 0.0000\n",
      "870/1000 train loss: 0.0001\n",
      "871/1000 train loss: 0.0002\n",
      "872/1000 train loss: 0.0000\n",
      "873/1000 train loss: 0.0001\n",
      "874/1000 train loss: 0.0000\n",
      "875/1000 train loss: 0.0001\n",
      "876/1000 train loss: 0.0000\n",
      "877/1000 train loss: 0.0001\n",
      "878/1000 train loss: 0.0000\n",
      "879/1000 train loss: 0.0001\n",
      "880/1000 train loss: 0.0003\n",
      "881/1000 train loss: 0.0000\n",
      "882/1000 train loss: 0.0002\n",
      "883/1000 train loss: 0.0002\n",
      "884/1000 train loss: 0.0000\n",
      "885/1000 train loss: 0.0001\n",
      "886/1000 train loss: 0.0012\n",
      "887/1000 train loss: 0.0001\n",
      "888/1000 train loss: 0.0001\n",
      "889/1000 train loss: 0.0002\n",
      "890/1000 train loss: 0.0004\n",
      "891/1000 train loss: 0.0014\n",
      "892/1000 train loss: 0.0002\n",
      "893/1000 train loss: 0.0001\n",
      "894/1000 train loss: 0.0002\n",
      "895/1000 train loss: 0.0001\n",
      "896/1000 train loss: 0.0002\n",
      "897/1000 train loss: 0.0000\n",
      "898/1000 train loss: 0.0001\n",
      "899/1000 train loss: 0.0001\n",
      "900/1000 train loss: 0.0000\n",
      "   validation loss: 0.1288 (accuracy 0.9700)\n",
      "901/1000 train loss: 0.0000\n",
      "902/1000 train loss: 0.0000\n",
      "903/1000 train loss: 0.0000\n",
      "904/1000 train loss: 0.0003\n",
      "905/1000 train loss: 0.0002\n",
      "906/1000 train loss: 0.0000\n",
      "907/1000 train loss: 0.0001\n",
      "908/1000 train loss: 0.0001\n",
      "909/1000 train loss: 0.0000\n",
      "910/1000 train loss: 0.0001\n",
      "911/1000 train loss: 0.0001\n",
      "912/1000 train loss: 0.0050\n",
      "913/1000 train loss: 0.0001\n",
      "914/1000 train loss: 0.0497\n",
      "915/1000 train loss: 0.0004\n",
      "916/1000 train loss: 0.0019\n",
      "917/1000 train loss: 0.0006\n",
      "918/1000 train loss: 0.0006\n",
      "919/1000 train loss: 0.0000\n",
      "920/1000 train loss: 0.0000\n",
      "921/1000 train loss: 0.0004\n",
      "922/1000 train loss: 0.0059\n",
      "923/1000 train loss: 0.0001\n",
      "924/1000 train loss: 0.0001\n",
      "925/1000 train loss: 0.0002\n",
      "926/1000 train loss: 0.0001\n",
      "927/1000 train loss: 0.0000\n",
      "928/1000 train loss: 0.0001\n",
      "929/1000 train loss: 0.0004\n",
      "930/1000 train loss: 0.0001\n",
      "931/1000 train loss: 0.0002\n",
      "932/1000 train loss: 0.0000\n",
      "933/1000 train loss: 0.0001\n",
      "934/1000 train loss: 0.0000\n",
      "935/1000 train loss: 0.0000\n",
      "936/1000 train loss: 0.0002\n",
      "937/1000 train loss: 0.0002\n",
      "938/1000 train loss: 0.0000\n",
      "939/1000 train loss: 0.0002\n",
      "940/1000 train loss: 0.0000\n",
      "941/1000 train loss: 0.0000\n",
      "942/1000 train loss: 0.0001\n",
      "943/1000 train loss: 0.0000\n",
      "944/1000 train loss: 0.0000\n",
      "945/1000 train loss: 0.0000\n",
      "946/1000 train loss: 0.0000\n",
      "947/1000 train loss: 0.0001\n",
      "948/1000 train loss: 0.0000\n",
      "949/1000 train loss: 0.0006\n",
      "950/1000 train loss: 0.0001\n",
      "951/1000 train loss: 0.0000\n",
      "952/1000 train loss: 0.0001\n",
      "953/1000 train loss: 0.0000\n",
      "954/1000 train loss: 0.0002\n",
      "955/1000 train loss: 0.0000\n",
      "956/1000 train loss: 0.0000\n",
      "957/1000 train loss: 0.0000\n",
      "958/1000 train loss: 0.0000\n",
      "959/1000 train loss: 0.0000\n",
      "960/1000 train loss: 0.0000\n",
      "961/1000 train loss: 0.0000\n",
      "962/1000 train loss: 0.0000\n",
      "963/1000 train loss: 0.0001\n",
      "964/1000 train loss: 0.0000\n",
      "965/1000 train loss: 0.0003\n",
      "966/1000 train loss: 0.0000\n",
      "967/1000 train loss: 0.0000\n",
      "968/1000 train loss: 0.0000\n",
      "969/1000 train loss: 0.0002\n",
      "970/1000 train loss: 0.0020\n",
      "971/1000 train loss: 0.0001\n",
      "972/1000 train loss: 0.0000\n",
      "973/1000 train loss: 0.0016\n",
      "974/1000 train loss: 0.0001\n",
      "975/1000 train loss: 0.0001\n",
      "976/1000 train loss: 0.0001\n",
      "977/1000 train loss: 0.0000\n",
      "978/1000 train loss: 0.0000\n",
      "979/1000 train loss: 0.0001\n",
      "980/1000 train loss: 0.0001\n",
      "981/1000 train loss: 0.0000\n",
      "982/1000 train loss: 0.0000\n",
      "983/1000 train loss: 0.0000\n",
      "984/1000 train loss: 0.0001\n",
      "985/1000 train loss: 0.0003\n",
      "986/1000 train loss: 0.0000\n",
      "987/1000 train loss: 0.0000\n",
      "988/1000 train loss: 0.0001\n",
      "989/1000 train loss: 0.0001\n",
      "990/1000 train loss: 0.0000\n",
      "991/1000 train loss: 0.0000\n",
      "992/1000 train loss: 0.0001\n",
      "993/1000 train loss: 0.0000\n",
      "994/1000 train loss: 0.0001\n",
      "995/1000 train loss: 0.0000\n",
      "996/1000 train loss: 0.0000\n",
      "997/1000 train loss: 0.0000\n",
      "998/1000 train loss: 0.0000\n",
      "999/1000 train loss: 0.0000\n",
      "1000/1000 train loss: 0.0001\n",
      "   validation loss: 0.1650 (accuracy 0.9700)\n"
     ]
    }
   ],
   "source": [
    "# Prepare data and build the TensorFlow graph\n",
    "data_lstm = Preprocessing(data_dir=data_dir,\n",
    "                          stopwords_file=stopwords_file,\n",
    "                          sequence_len=sequence_len,\n",
    "                          test_size=test_size,\n",
    "                          val_samples=batch_size,\n",
    "                          n_samples=n_samples,\n",
    "                          random_state=100)\n",
    "\n",
    "lstm_model = LSTM_RNN_Network(hidden_size=[hidden_size],\n",
    "                              vocab_size=data_lstm.vocab_size,\n",
    "                              embedding_size=embedding_size,\n",
    "                              max_length=data_lstm.sequence_len,\n",
    "                              learning_rate=learning_rate)\n",
    "\n",
    "\n",
    "# Train the model\n",
    "sess = tf.Session()\n",
    "# Initializing the variables\n",
    "init_op = tf.global_variables_initializer()\n",
    "sess.run(init_op)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "x_val, y_val, val_seq_len = data_lstm.get_val_data()\n",
    "train_writer.add_graph(lstm_model.input.graph)\n",
    "\n",
    "\n",
    "# Lists\n",
    "train_loss_list = []\n",
    "val_loss_list = []\n",
    "step_list = []\n",
    "sub_step_list = []\n",
    "step = 0\n",
    "\n",
    "\n",
    "for i in range(train_steps):\n",
    "    # Perform the training step\n",
    "    x_train, y_train, train_seq_len = data_lstm.next_batch(batch_size)\n",
    "    train_loss, _, summary = sess.run([lstm_model.loss, lstm_model.train_step, lstm_model.merged],\n",
    "                                      feed_dict={lstm_model.input: x_train,\n",
    "                                                 lstm_model.target: y_train,\n",
    "                                                 lstm_model.seq_len: train_seq_len,\n",
    "                                                 lstm_model.dropout_keep_prob: dropout_keep_prob})\n",
    "    train_writer.add_summary(summary, i)  # Write train summary for step i (TensorBoard visualization)\n",
    "    train_loss_list.append(train_loss)\n",
    "    step_list.append(i)\n",
    "\n",
    "    print('{0}/{1} train loss: {2:.4f}'.format(i + 1, train_steps, train_loss))\n",
    "\n",
    "    # Check the validation performance\n",
    "    if (i + 1) % validate_every == 0:\n",
    "        val_loss, accuracy, summary = sess.run([lstm_model.loss, lstm_model.accuracy, lstm_model.merged],\n",
    "                                               feed_dict={lstm_model.input: x_val,\n",
    "                                                          lstm_model.target: y_val,\n",
    "                                                          lstm_model.seq_len: val_seq_len,\n",
    "                                                          lstm_model.dropout_keep_prob: 1})\n",
    "        validation_writer.add_summary(summary, i)  # Write validation summary for step i (TensorBoard visualization)\n",
    "        print('   validation loss: {0:.4f} (accuracy {1:.4f})'.format(val_loss, accuracy))\n",
    "        step = step + 1\n",
    "        val_loss_list.append(val_loss)\n",
    "        sub_step_list.append(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot loss over time\n",
    "plt.plot(step_list, train_loss_list, 'r--', label='LSTM training loss per iteration', linewidth=4)\n",
    "plt.title('LSTM training loss per iteration')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Training loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "# Plot accuracy over time\n",
    "plt.plot(sub_step_list, val_loss_list, 'r--', label='LSTM validation loss per validatin interval', linewidth=4)\n",
    "plt.title('LSTM validation loss per validatin interval')\n",
    "plt.xlabel('Validatin interval')\n",
    "plt.ylabel('Validation loss')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in: checkpoints/1603011876\n"
     ]
    }
   ],
   "source": [
    "# Save the model such as 'checkpoints/1603001049' in the current directory. \n",
    "checkpoint_file = '{}/model.ckpt'.format(model_dir)\n",
    "save_path = saver.save(sess, checkpoint_file)\n",
    "print('Model saved in: {0}'.format(model_dir))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
